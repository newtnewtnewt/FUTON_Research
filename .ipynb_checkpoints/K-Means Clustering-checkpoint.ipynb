{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#  FUTON Model MDP + Q-Learning Creation Script\n",
    "#  A Research Project conducted by Noah Dunn \n",
    "###\n",
    "\n",
    "# Import the standard tools for working with Pandas dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shelve\n",
    "# Import the MDP toolbox that contains a method for conducting Q-Learning\n",
    "# Tool can be found here: https://github.com/sawcordwell/pymdptoolbox\n",
    "# Documentation for the tool can be found here \n",
    "import mdptoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The Data File that will be used to conduct the experiments\n",
    "patientdata = pd.read_csv(\"G:/MIMIC-ALL/MIMIC-PATIENTS/patient_data_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "#  An MDP, or Markov Decision Process is used to model relationships between various states and actions.\n",
    "#  A state can be thought of in medical solution as a patient's diagnosis based on current vitals and state of being. \n",
    "#  An action can be thought of as a change in current diagnosis based on one of those vitals.\n",
    "#  The inspirations for the bulk of this code came from Komorowksi's AI Clinician which can be found \n",
    "#  here: https://github.com/matthieukomorowski/AI_Clinician/blob/master/AIClinician_core_160219.m\n",
    "###\n",
    "\n",
    "###\n",
    "# Begin by establishing some global variables for use in the MDP creation\n",
    "###\n",
    "mdp_count = 500            # The number of repititions we want/count of MDPs we need to create \n",
    "clustering_iter = 32       # The number of times clustering will be conducted\n",
    "cluster_sample = 0.25      # Proportion of the data used for clustering\n",
    "gamma = 0.99               # How close we desire clusters to be in similarity (Percentage)\n",
    "transition_threshold = 5   # The cutoff value for the transition matrix\n",
    "final_policies = 1         # The number of policies we would like to end up with\n",
    "state_count = 750          # The number of distinct states\n",
    "action_count = 5           # Number of actions per state (reccommended 2 to 10)\n",
    "crossval_iter = 10         # Number of crossvalidation runs (Default is 80% Train, 20% Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Data structures to hold our interim data\n",
    "###\n",
    "\n",
    "# Create the structures and fill them with NaN values\n",
    "optimal_actions = np.empty((state_count + 2, mdp_count,))  # Not sure the significance of the 2 yet\n",
    "optimal_actions[:] = np.nan\n",
    "\n",
    "\n",
    "model_data = np.empty((mdp_count*2, 30,))\n",
    "model_data[:] = np.nan\n",
    "\n",
    "bestmodels_data = np.empty((mdp_count, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21463\n"
     ]
    }
   ],
   "source": [
    "# Grab list of unique patient ICU stay IDs\n",
    "icu_ids = patientdata['icustayid'].unique()\n",
    "# Number of patients to be used for states\n",
    "id_count = icu_ids.size\n",
    "print(id_count)\n",
    "\n",
    "# Create a data structure to representing all patients\n",
    "patient_idxs = np.empty((id_count, mdp_count,))\n",
    "patient_idxs[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gender  mechvent  max_dose_vaso  re_admission  qSOFAFlag  SOFAFlag\n",
      "0            0         1            0.0             0          1         0\n",
      "1            0         1            0.0             0          1         1\n",
      "2            0         1            0.0             0          1         1\n",
      "3            0         1            0.0             0          1         1\n",
      "4            0         1            0.0             0          1         1\n",
      "...        ...       ...            ...           ...        ...       ...\n",
      "238325       0         0            0.0             0          1         0\n",
      "238326       0         0            0.0             0          1         0\n",
      "238327       0         0            0.0             0          1         0\n",
      "238328       0         0            0.0             0          1         0\n",
      "238329       0         0            0.0             0          1         0\n",
      "\n",
      "[238330 rows x 6 columns] \n",
      "                 age  Weight_kg        GCS         HR       SysBP     MeanBP  \\\n",
      "0       17639.82644  75.062500  10.000000  77.800000  119.000000  82.000000   \n",
      "1       17639.82644  78.699997  10.000000  79.125000  111.375000  78.000000   \n",
      "2       17639.82644  78.699997  10.166667  77.833333  104.000000  76.000000   \n",
      "3       17639.82644  78.699997  11.000000  74.750000  121.500000  96.000000   \n",
      "4       17639.82644  78.699997  14.200000  98.200000  131.100000  98.600000   \n",
      "...             ...        ...        ...        ...         ...        ...   \n",
      "238325   8538.73934  74.000000  15.000000  90.750000  142.500000  85.500000   \n",
      "238326   8538.73934  88.400002  15.000000  86.250000  149.000000  87.000000   \n",
      "238327   8538.73934  73.000000  15.000000  84.000000  147.333333  98.111111   \n",
      "238328   8538.73934  73.000000  15.000000  68.750000  146.000000  99.333333   \n",
      "238329   8538.73934  73.000000  15.000000  75.666667  139.333333  89.000000   \n",
      "\n",
      "            DiaBP         RR     Temp_C  FiO2_1  ...      paCO2  Arterial_BE  \\\n",
      "0       63.200000  23.800000  37.422223    0.40  ...  38.750000       -1.375   \n",
      "1       59.500000  21.000000  37.319443    0.40  ...  40.000000        5.000   \n",
      "2       59.333333  20.333333  37.240740    0.40  ...  40.000000        5.000   \n",
      "3       80.000000  19.750000  37.333332    0.40  ...  40.000000        5.000   \n",
      "4       80.300000  23.400000  37.438887    0.61  ...  36.000000        3.000   \n",
      "...           ...        ...        ...     ...  ...        ...          ...   \n",
      "238325  70.500000  19.250000  37.083333    0.21  ...  38.000000        1.000   \n",
      "238326  70.666667  23.750000  36.999999    0.21  ...  34.000000        0.000   \n",
      "238327  78.333333  18.000000  36.822222    0.21  ...  51.363636        0.000   \n",
      "238328  83.500000  17.750000  36.555557    0.21  ...  51.363636        0.000   \n",
      "238329  76.333333  20.000000  36.555557    0.21  ...  51.363636        0.000   \n",
      "\n",
      "             HCO3  Arterial_lactate  SOFA  SIRS  Shock_Index    PaO2_FiO2  \\\n",
      "0       21.000000          1.900000     3     1     0.653782   434.687493   \n",
      "1       27.000000          1.300000     7     2     0.710438   207.499997   \n",
      "2       27.000000          1.900000     7     2     0.748397   207.499997   \n",
      "3       27.000000          1.200000     7     1     0.615226   207.499997   \n",
      "4       32.000000          2.200000     6     3     0.749047   165.573772   \n",
      "...           ...               ...   ...   ...          ...          ...   \n",
      "238325  22.333333          2.600000     1     2     0.636842   385.714286   \n",
      "238326  25.000000          2.600000     0     2     0.578859  1390.476190   \n",
      "238327  27.000000          1.354545     5     1     0.570136   314.718615   \n",
      "238328  27.000000          1.354545     1     1     0.470890   314.718615   \n",
      "238329  27.000000          1.354545     1     2     0.543062   314.718615   \n",
      "\n",
      "        cumulated_balance  qSOFA  \n",
      "0               -4690.000      2  \n",
      "1               -5215.000      1  \n",
      "2               -6015.000      1  \n",
      "3               -6615.000      1  \n",
      "4               -7055.000      2  \n",
      "...                   ...    ...  \n",
      "238325          -2546.417      0  \n",
      "238326          -3246.417      1  \n",
      "238327          -3246.417      0  \n",
      "238328          -3666.417      0  \n",
      "238329          -4186.417      0  \n",
      "\n",
      "[238330 rows x 33 columns] \n",
      "              SpO2    BUN  Creatinine   SGOT   SGPT  Total_bili  INR  \\\n",
      "0       98.400000  15.75       0.975  151.2  145.4        1.48  1.1   \n",
      "1       97.000000  10.00       0.700   38.0   23.0        4.90  1.3   \n",
      "2       97.166667  10.00       0.700   38.0   23.0        4.90  1.5   \n",
      "3       97.000000  10.00       0.700   38.0   23.0        4.90  1.1   \n",
      "4       97.400000  10.00       0.700   38.0   23.0        4.90  1.1   \n",
      "...           ...    ...         ...    ...    ...         ...  ...   \n",
      "238325  98.000000   6.00       0.800  139.0   46.0        0.20  1.0   \n",
      "238326  96.666667   6.00       0.800   19.0   19.0        0.20  1.1   \n",
      "238327  98.000000   6.00       0.800   60.0   31.0        0.80  1.7   \n",
      "238328  99.000000   6.00       0.800   60.0   31.0        0.80  1.7   \n",
      "238329  98.000000   6.00       0.800   60.0   31.0        0.80  1.7   \n",
      "\n",
      "        input_total  input_4hourly  output_total  output_4hourly  \n",
      "0          6297.000           30.0       10987.0           580.0  \n",
      "1          6347.000           50.0       11562.0           575.0  \n",
      "2          6397.000           50.0       12412.0           850.0  \n",
      "3          6447.000           50.0       13062.0           650.0  \n",
      "4          6477.000           30.0       13532.0           470.0  \n",
      "...             ...            ...           ...             ...  \n",
      "238325     2113.583            0.0        4660.0           600.0  \n",
      "238326     2113.583            0.0        5360.0           700.0  \n",
      "238327     2113.583            0.0        5360.0             0.0  \n",
      "238328     2113.583            0.0        5780.0           420.0  \n",
      "238329     2113.583            0.0        6300.0           520.0  \n",
      "\n",
      "[238330 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# All our columns are broken up into 3 distinct categories:\n",
    "# 1. Binary values (0 or 1)\n",
    "# 2. Standard Ranges (Plain old Integers + Decimals)\n",
    "# 3. Logarthmic Values (columnvalue = log(columnvalue))\n",
    "\n",
    "colbin = ['gender','mechvent','max_dose_vaso','re_admission', 'qSOFAFlag', 'SOFAFlag']\n",
    "colnorm = ['age','Weight_kg','GCS','HR','SysBP','MeanBP','DiaBP','RR','Temp_C','FiO2_1',\n",
    "    'Potassium','Sodium','Chloride','Glucose','Magnesium','Calcium',\n",
    "    'Hb','WBC_count','Platelets_count','PTT','PT','Arterial_pH','paO2','paCO2',\n",
    "    'Arterial_BE','HCO3','Arterial_lactate','SOFA','SIRS','Shock_Index','PaO2_FiO2','cumulated_balance', 'qSOFA'];\n",
    "collog=['SpO2','BUN','Creatinine','SGOT','SGPT','Total_bili','INR','input_total','input_4hourly','output_total','output_4hourly'];\n",
    "\n",
    "# Create seperate dataframes for each of the columns\n",
    "colbin_df = patientdata[colbin]\n",
    "colnorm_df = patientdata[colnorm]\n",
    "collog_df = patientdata[collog]\n",
    "\n",
    "# Let's make sure we have what we need\n",
    "print(colbin_df, \"\\n\", colnorm_df, \"\\n\", collog_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gender  mechvent  max_dose_vaso  re_admission  qSOFAFlag  SOFAFlag  \\\n",
      "0            0         1            0.0             0          1         0   \n",
      "1            0         1            0.0             0          1         1   \n",
      "2            0         1            0.0             0          1         1   \n",
      "3            0         1            0.0             0          1         1   \n",
      "4            0         1            0.0             0          1         1   \n",
      "...        ...       ...            ...           ...        ...       ...   \n",
      "238325       0         0            0.0             0          1         0   \n",
      "238326       0         0            0.0             0          1         0   \n",
      "238327       0         0            0.0             0          1         0   \n",
      "238328       0         0            0.0             0          1         0   \n",
      "238329       0         0            0.0             0          1         0   \n",
      "\n",
      "                age  Weight_kg        GCS         HR  ...    BUN  Creatinine  \\\n",
      "0       17639.82644  75.062500  10.000000  77.800000  ...  15.75       0.975   \n",
      "1       17639.82644  78.699997  10.000000  79.125000  ...  10.00       0.700   \n",
      "2       17639.82644  78.699997  10.166667  77.833333  ...  10.00       0.700   \n",
      "3       17639.82644  78.699997  11.000000  74.750000  ...  10.00       0.700   \n",
      "4       17639.82644  78.699997  14.200000  98.200000  ...  10.00       0.700   \n",
      "...             ...        ...        ...        ...  ...    ...         ...   \n",
      "238325   8538.73934  74.000000  15.000000  90.750000  ...   6.00       0.800   \n",
      "238326   8538.73934  88.400002  15.000000  86.250000  ...   6.00       0.800   \n",
      "238327   8538.73934  73.000000  15.000000  84.000000  ...   6.00       0.800   \n",
      "238328   8538.73934  73.000000  15.000000  68.750000  ...   6.00       0.800   \n",
      "238329   8538.73934  73.000000  15.000000  75.666667  ...   6.00       0.800   \n",
      "\n",
      "         SGOT   SGPT  Total_bili  INR  input_total  input_4hourly  \\\n",
      "0       151.2  145.4        1.48  1.1     6297.000           30.0   \n",
      "1        38.0   23.0        4.90  1.3     6347.000           50.0   \n",
      "2        38.0   23.0        4.90  1.5     6397.000           50.0   \n",
      "3        38.0   23.0        4.90  1.1     6447.000           50.0   \n",
      "4        38.0   23.0        4.90  1.1     6477.000           30.0   \n",
      "...       ...    ...         ...  ...          ...            ...   \n",
      "238325  139.0   46.0        0.20  1.0     2113.583            0.0   \n",
      "238326   19.0   19.0        0.20  1.1     2113.583            0.0   \n",
      "238327   60.0   31.0        0.80  1.7     2113.583            0.0   \n",
      "238328   60.0   31.0        0.80  1.7     2113.583            0.0   \n",
      "238329   60.0   31.0        0.80  1.7     2113.583            0.0   \n",
      "\n",
      "        output_total  output_4hourly  \n",
      "0            10987.0           580.0  \n",
      "1            11562.0           575.0  \n",
      "2            12412.0           850.0  \n",
      "3            13062.0           650.0  \n",
      "4            13532.0           470.0  \n",
      "...              ...             ...  \n",
      "238325        4660.0           600.0  \n",
      "238326        5360.0           700.0  \n",
      "238327        5360.0             0.0  \n",
      "238328        5780.0           420.0  \n",
      "238329        6300.0           520.0  \n",
      "\n",
      "[238330 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Rearrange the dataframe in order of binary, normal, and log data from left to right\n",
    "MIMIC_raw = pd.concat([colbin_df, colnorm_df, collog_df], axis=1)\n",
    "print(MIMIC_raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gender  mechvent  max_dose_vaso  re_admission  qSOFAFlag  SOFAFlag  \\\n",
      "0         -0.5       0.5           -0.5          -0.5        0.5      -0.5   \n",
      "1         -0.5       0.5           -0.5          -0.5        0.5       0.5   \n",
      "2         -0.5       0.5           -0.5          -0.5        0.5       0.5   \n",
      "3         -0.5       0.5           -0.5          -0.5        0.5       0.5   \n",
      "4         -0.5       0.5           -0.5          -0.5        0.5       0.5   \n",
      "...        ...       ...            ...           ...        ...       ...   \n",
      "238325    -0.5      -0.5           -0.5          -0.5        0.5      -0.5   \n",
      "238326    -0.5      -0.5           -0.5          -0.5        0.5      -0.5   \n",
      "238327    -0.5      -0.5           -0.5          -0.5        0.5      -0.5   \n",
      "238328    -0.5      -0.5           -0.5          -0.5        0.5      -0.5   \n",
      "238329    -0.5      -0.5           -0.5          -0.5        0.5      -0.5   \n",
      "\n",
      "             age  Weight_kg       GCS        HR  ...       BUN  Creatinine  \\\n",
      "0      -0.973100  -0.318414 -0.687933 -0.569736  ... -0.545751   -0.214781   \n",
      "1      -0.973100  -0.169199 -0.687933 -0.491800  ... -1.189188   -0.679473   \n",
      "2      -0.973100  -0.169199 -0.640362 -0.567776  ... -1.189188   -0.679473   \n",
      "3      -0.973100  -0.169199 -0.402506 -0.749137  ... -1.189188   -0.679473   \n",
      "4      -0.973100  -0.169199  0.510859  0.630189  ... -1.189188   -0.679473   \n",
      "...          ...        ...       ...       ...  ...       ...         ...   \n",
      "238325 -2.467202  -0.361999  0.739200  0.191981  ... -1.909177   -0.494229   \n",
      "238326 -2.467202   0.228708  0.739200 -0.072708  ... -1.909177   -0.494229   \n",
      "238327 -2.467202  -0.403020  0.739200 -0.205053  ... -1.909177   -0.494229   \n",
      "238328 -2.467202  -0.403020  0.739200 -1.102056  ... -1.909177   -0.494229   \n",
      "238329 -2.467202  -0.403020  0.739200 -0.695219  ... -1.909177   -0.494229   \n",
      "\n",
      "            SGOT      SGPT  Total_bili       INR  input_total  input_4hourly  \\\n",
      "0       0.977035  1.112233    0.334065 -0.692745     0.410209       0.096264   \n",
      "1      -0.268657 -0.443987    1.387969 -0.214109     0.412665       0.240649   \n",
      "2      -0.268657 -0.443987    1.387969  0.200505     0.415103       0.240649   \n",
      "3      -0.268657 -0.443987    1.387969 -0.692745     0.417521       0.240649   \n",
      "4      -0.268657 -0.443987    1.387969 -0.692745     0.418963       0.096264   \n",
      "...          ...       ...         ...       ...          ...            ...   \n",
      "238325  0.901093  0.140315   -1.185843 -0.962914     0.071129      -1.521065   \n",
      "238326 -0.892408 -0.604775   -1.185843 -0.692745     0.071129      -1.521065   \n",
      "238327  0.143061 -0.192522   -0.180792  0.566220     0.071129      -1.521065   \n",
      "238328  0.143061 -0.192522   -0.180792  0.566220     0.071129      -1.521065   \n",
      "238329  0.143061 -0.192522   -0.180792  0.566220     0.071129      -1.521065   \n",
      "\n",
      "        output_total  output_4hourly  \n",
      "0           0.757770        0.733745  \n",
      "1           0.771262        0.731161  \n",
      "2           0.790024        0.847813  \n",
      "3           0.803524        0.767750  \n",
      "4           0.812873        0.670986  \n",
      "...              ...             ...  \n",
      "238325      0.530930        0.743862  \n",
      "238326      0.567943        0.789867  \n",
      "238327      0.567943       -1.852903  \n",
      "238328      0.587895        0.637420  \n",
      "238329      0.610678        0.701156  \n",
      "\n",
      "[238330 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# We want a Z-Score for every item. This a measure of variance to see how far a value is from the mean\n",
    "\n",
    "# Scipy provides a library to execute this kind of thing\n",
    "from scipy.stats import zscore\n",
    "# We need to normalize binaries to -0.5 and 0.5 for later use\n",
    "MIMIC_zscores = MIMIC_raw\n",
    "\n",
    "# No need for the zscore algorithm here, -0.5 and 0.5 suffice\n",
    "MIMIC_zscores[colbin] = MIMIC_zscores[colbin] - 0.5\n",
    "\n",
    "# Recall these columns are logarithmic, so they needed converted back for proper Z-Scoring (+ 0.1 to avoid log(0))\n",
    "MIMIC_zscores[collog] = np.log(MIMIC_zscores[collog] + 0.1).apply(zscore)\n",
    "\n",
    "# Normal column requires no modifications. Z-Scores are calculated as normal\n",
    "MIMIC_zscores[colnorm] = MIMIC_zscores[colnorm].apply(zscore)\n",
    "print(MIMIC_zscores)\n",
    "\n",
    "# We want Re Admission and fluid intake scaled Similarly to the other variables\n",
    "MIMIC_zscores['re_admission'] = np.log(MIMIC_zscores['re_admission'] + 0.6)\n",
    "# Apply a scalar to fluid intake\n",
    "MIMIC_zscores['input_total'] = 2 * MIMIC_zscores['input_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Percentage: 0.19945953501374458\n",
      "Training Percentage: 0.8005404649862554\n"
     ]
    }
   ],
   "source": [
    "### The main loop to generate all possible models\n",
    "\n",
    "num_rows = id_count  # Total Number of Patients to divy data up\n",
    "testing_flag = 1     # The random number we use to identify a patient used for testing\n",
    "\n",
    "# TODO: Change this to 1 in MDP_COUNT\n",
    "#for model in range(1, 2): #mdp_count):\n",
    "train_ids = []       # A list containing all training ids from the icu_ids list\n",
    "test_ids =[]         # A list containing all testing ids from the icu_ids list\n",
    "\n",
    "# We want approximate 20% test, 80% train, so we random numbers 1-5\n",
    "# 1s Represent data points that will be used to test, 2-5 will be used to train\n",
    "group_ids = pd.DataFrame([int(np.floor(5 * np.random.random() + 1)) for i in range(1, id_count + 1)])\n",
    "icu_pair_set = pd.concat([pd.DataFrame(icu_ids), group_ids], axis=1, sort=False)\n",
    "icu_pair_set.columns = ['id', 'fil_val']\n",
    "train_ids =  icu_pair_set[icu_pair_set['fil_val'] != testing_flag]\n",
    "test_ids = icu_pair_set[icu_pair_set['fil_val'] == testing_flag]\n",
    "\n",
    "# We want to insure that the testing patients + training patients = total patients\n",
    "if (train_ids['id'].size + test_ids['id'].size) != id_count:\n",
    "    print(\"The testing and training set do not add up to the total set\")\n",
    "    exit()\n",
    "\n",
    "# Percentage for testing should be about 20%, Training about 80%\n",
    "print(\"Testing Percentage: \" + str((test_ids['id'].size / id_count)))\n",
    "print(\"Training Percentage: \" + str((train_ids['id'].size / id_count)))\n",
    "\n",
    "# After grabbing all the IDs, we want to flag all the rows that are train or test\n",
    "train_flag = patientdata['icustayid'].isin(train_ids['id'])\n",
    "test_flag = patientdata['icustayid'].isin(test_ids['id'])\n",
    "\n",
    "#Validating that all data is being selected, and that the train and test sets are perfect opposites\n",
    "if patientdata['icustayid'].size != train_flag.size or not((train_flag.equals(~test_flag))):\n",
    "    print(\"Not all rows were grabbed properly, there is something wrong with the split\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Z-Scores for the training set and the testing set\n",
    "train_zscores = MIMIC_zscores[train_flag]\n",
    "test_zscores = MIMIC_zscores[test_flag]\n",
    "\n",
    "# Validate all data is selected\n",
    "if(train_zscores.size + test_zscores.size != MIMIC_zscores.size):\n",
    "    print(\"The Z-Scores are all evenly distributed\")\n",
    "    exit()\n",
    "\n",
    "    \n",
    "# The blocs of relevance in order based on the train and test set\n",
    "# These will be used to build relevant data frames later down\n",
    "train_blocs = patientdata[train_flag]['bloc']\n",
    "test_blocs = patientdata[test_flag]['bloc']\n",
    "\n",
    "# Doing the same with the patient ids\n",
    "train_id_list = patientdata[train_flag]['icustayid']\n",
    "test_id_list = patientdata[test_flag]['icustayid']\n",
    "\n",
    "# Grabbing the boolean values for the patients who died within 90 days in the training set\n",
    "train_90d = patientdata[train_flag]['mortality_90d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Data used for the Sample: 0.251288727440708\n"
     ]
    }
   ],
   "source": [
    "# Next, we want to sample the existing training set to only pick cluster_sample percent to use\n",
    "\n",
    "# We want to flag all the data points in the train_zscores set that will be used to create the MDP\n",
    "\n",
    "# Note: len(train_zscores.index) is the fastest way to get the number of rows in a dataframe in pandas\n",
    "\n",
    "# Additional Note: np.floor(np.random.random() + cluster_sample) is a computationally speedy way to get an approximate\n",
    "# percentage sample from a proportion value (cluster_sample). If cluster sample is 0.25, approximately 25% of the values\n",
    "# will be flagged as a 1, making it into the sample training set\n",
    "sample_train_flags = [bool(np.floor(np.random.random() + cluster_sample)) for i in range(len(train_zscores.index))]\n",
    "\n",
    "# It's good to know how much of the data was selected as sample\n",
    "print(\"Proportion of Train Data used for the Sample: \" + str(sample_train_flags.count(True)/len(sample_train_flags)))\n",
    "\n",
    "# The actual set to use\n",
    "sample_train_set = train_zscores[sample_train_flags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to prepare a proper set of states, we want to use k-means clustering to group various patients into \n",
    "# distinct states based on Z-Scores\n",
    "\n",
    "# K-Means or K-Means++ is a technique used to condense very diverse and sparse data into similar groups called 'clusters'\n",
    "# The K-means algorithm will create k clusters from N data points. In the case of this research,\n",
    "# the algorithm divides patients into groups that have similar data (age, blood pressure, etc..) and creates a faux 'point'\n",
    "# at the center of that particular clustering of data\n",
    "\n",
    "\n",
    "# Skikit offers a solution to perform K-Means++ clustering\n",
    "from sklearn.cluster import KMeans\n",
    "# The KMeans takes three 'settings' arguments\n",
    "# 1. n_clusters: The number of clusters (later to be used as states), that we desire the algorithm to produce\n",
    "# this value has been preset to state_count which is 750\n",
    "# 2. max_iter: How many times each round of k-means clustering will make adjustments, set at 10,000 in my case\n",
    "# 3. n_init: The number of max_iter batches that will be conducted in a row. The best of these will be chosen\n",
    "# and saved in the variable clusters_models\n",
    "clusters_models = KMeans(n_clusters=state_count, max_iter=10000, n_init=clustering_iter).fit(sample_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321 229 527 ... 137 573 155]\n",
      "[[-0.2254902  -0.32352941 -0.42817647 ... -0.07048865  0.20045151\n",
      "   0.04158715]\n",
      " [ 0.09405941 -0.04455446 -0.47672277 ...  0.66545596  0.32843116\n",
      "   0.42501051]\n",
      " [ 0.04545455 -0.15454545 -0.49425455 ...  0.30664516  0.28904419\n",
      "   0.42852166]\n",
      " ...\n",
      " [-0.34615385 -0.38461538 -0.46365385 ... -1.47820946 -0.18871191\n",
      "   0.04611651]\n",
      " [ 0.01351351 -0.01351351 -0.46678378 ...  0.34582232  0.109389\n",
      "   0.14752571]\n",
      " [ 0.5        -0.5        -0.5        ... -1.52106461 -2.31206609\n",
      "  -1.85290276]]\n"
     ]
    }
   ],
   "source": [
    "print(clusters_models.labels_)\n",
    "print(clusters_models.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python has object serialization to make write/reads fasters, in the form of pickle\n",
    "import pickle\n",
    "\n",
    "# Save the important data (clusters created as a result of the K-Means operations)\n",
    "# This process takes quite a while. This will provide a checkpoint to decrease compute time\n",
    "# until the code is put into dev.\n",
    "with open('cluster_labels.txt', 'wb') as fp:\n",
    "    pickle.dump(clusters_models.labels_, fp)\n",
    "with open('cluster_centers.txt', 'wb') as fp:\n",
    "    pickle.dump(clusters_models.cluster_centers_, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
